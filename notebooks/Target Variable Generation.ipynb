{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b32419a5-165a-405f-87e5-74a859e0552c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "CREATE TARGET VARIABLE FOR RISK CLASSIFICATION\n",
      "======================================================================\n",
      "\n",
      "Loading data from: data/processed/reports_with_features.csv\n",
      "Loaded 3000 rows\n",
      "======================================================================\n",
      "EXPLORING POTENTIAL TARGET VARIABLES\n",
      "======================================================================\n",
      "\n",
      "Dataset has 3000 rows and 19 columns\n",
      "\n",
      "All columns: ['id', 'timestamp', 'style', 'topic', 'sentiment', 'load_factor', 'agents', 'capacity', 'text', 'style_id', 'topic_id', 'sentiment_id', 'cleaned_text', 'risk_high_severity_count', 'risk_violation_count', 'risk_financial_count', 'risk_temporal_count', 'risk_density', 'text_length']\n",
      "\n",
      "✓ Found potential target columns:\n",
      "  - risk_high_severity_count\n",
      "    Unique values: [0]\n",
      "    Value counts:\n",
      "risk_high_severity_count\n",
      "0    3000\n",
      "Name: count, dtype: int64\n",
      "\n",
      "  - risk_violation_count\n",
      "    Unique values: [0]\n",
      "    Value counts:\n",
      "risk_violation_count\n",
      "0    3000\n",
      "Name: count, dtype: int64\n",
      "\n",
      "  - risk_financial_count\n",
      "    Unique values: [0]\n",
      "    Value counts:\n",
      "risk_financial_count\n",
      "0    3000\n",
      "Name: count, dtype: int64\n",
      "\n",
      "  - risk_temporal_count\n",
      "    Unique values: [0]\n",
      "    Value counts:\n",
      "risk_temporal_count\n",
      "0    3000\n",
      "Name: count, dtype: int64\n",
      "\n",
      "  - risk_density\n",
      "    Unique values: [0.]\n",
      "    Value counts:\n",
      "risk_density\n",
      "0.0    3000\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "======================================================================\n",
      "GENERATING TARGET VARIABLE OPTIONS\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "OPTION 1: CREATE TARGET FROM RISK FEATURES\n",
      "======================================================================\n",
      "\n",
      "Using risk features: ['risk_high_severity_count', 'risk_violation_count', 'risk_financial_count', 'risk_temporal_count', 'risk_density']\n",
      "\n",
      "Composite risk score statistics:\n",
      "  Min:  0.0000\n",
      "  Mean: 0.0000\n",
      "  Max:  0.0000\n",
      "  Threshold (90th percentile): 0.0000\n",
      "\n",
      "Risk label distribution:\n",
      "risk_label\n",
      "1    3000\n",
      "Name: count, dtype: int64\n",
      "\n",
      "  Low Risk (0):  0 (0.0%)\n",
      "  High Risk (1): 3000 (100.0%)\n",
      "\n",
      "======================================================================\n",
      "OPTION 2: CREATE TARGET FROM SENTIMENT\n",
      "======================================================================\n",
      "\n",
      "Sentiment values: ['optimistic' 'cautious' 'concerned' 'neutral']\n",
      "Warning: 2269 unmapped sentiment values\n",
      "\n",
      "Risk label from sentiment distribution:\n",
      "risk_label_from_sentiment\n",
      "0.0    731\n",
      "Name: count, dtype: int64\n",
      "\n",
      "======================================================================\n",
      "OPTION 3: CREATE TARGET FROM LOAD FACTOR\n",
      "======================================================================\n",
      "\n",
      "Load factor statistics:\n",
      "  Min:  0.0100\n",
      "  Mean: 0.2878\n",
      "  Max:  0.8200\n",
      "\n",
      "Using threshold: 0.8\n",
      "Risk label from load factor distribution:\n",
      "risk_label_from_load\n",
      "0    2996\n",
      "1       4\n",
      "Name: count, dtype: int64\n",
      "\n",
      "======================================================================\n",
      "OPTION 4: CREATE SYNTHETIC TARGET (DEMONSTRATION)\n",
      "======================================================================\n",
      "\n",
      "Creating synthetic labels with ~2% high-risk cases\n",
      "\n",
      "Synthetic risk label distribution:\n",
      "risk_label_synthetic\n",
      "0    2940\n",
      "1      60\n",
      "Name: count, dtype: int64\n",
      "\n",
      "======================================================================\n",
      "CREATING VISUALIZATIONS\n",
      "======================================================================\n",
      "  Saved: figures/risk_features_by_risk_label.png\n",
      "  Saved: figures/risk_features_by_risk_label_from_load.png\n",
      "  Saved: figures/risk_features_by_risk_label_synthetic.png\n",
      "  Saved: figures/label_distributions_comparison.png\n",
      "\n",
      "======================================================================\n",
      "RECOMMENDATION\n",
      "======================================================================\n",
      "\n",
      "Based on your data, I recommend using: 'risk_label'\n",
      "(Created from composite risk features)\n",
      "\n",
      "This approach:\n",
      "  ✓ Uses your actual risk features\n",
      "  ✓ Creates realistic separation between classes\n",
      "  ✓ Maintains interpretability\n",
      "\n",
      "✓ Saved dataset with labels to: data/processed/reports_with_features_and_labels.csv\n",
      "\n",
      "======================================================================\n",
      "NEXT STEPS\n",
      "======================================================================\n",
      "\n",
      "1. Review the generated labels\n",
      "2. If satisfied, update script 03 to use this file:\n",
      "   data_path = 'data/processed/reports_with_features_and_labels.csv'\n",
      "3. Or manually rename the column you want to use as 'risk_label'\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Create Target Variable Script\n",
    "==============================\n",
    "Creates a risk label target variable for your dataset based on \n",
    "available features or columns.\n",
    "\n",
    "Part of: Policy Risk Inference from Simulated Reports\n",
    "Author: William V. Fullerton\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "\n",
    "def explore_potential_targets(df):\n",
    "    \"\"\"Explore which columns could serve as target variable.\"\"\"\n",
    "    print(\"=\"*70)\n",
    "    print(\"EXPLORING POTENTIAL TARGET VARIABLES\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    print(f\"\\nDataset has {len(df)} rows and {len(df.columns)} columns\")\n",
    "    print(f\"\\nAll columns: {list(df.columns)}\")\n",
    "    \n",
    "    # Look for obvious target candidates\n",
    "    potential_targets = []\n",
    "    \n",
    "    for col in df.columns:\n",
    "        col_lower = col.lower()\n",
    "        if any(keyword in col_lower for keyword in ['risk', 'label', 'target', 'class', 'severity']):\n",
    "            potential_targets.append(col)\n",
    "    \n",
    "    if potential_targets:\n",
    "        print(f\"\\n✓ Found potential target columns:\")\n",
    "        for col in potential_targets:\n",
    "            print(f\"  - {col}\")\n",
    "            print(f\"    Unique values: {df[col].unique()[:10]}\")\n",
    "            print(f\"    Value counts:\\n{df[col].value_counts()}\\n\")\n",
    "    else:\n",
    "        print(\"\\n⚠ No obvious target column found\")\n",
    "        print(\"\\nWe'll need to create one based on your features or metadata\")\n",
    "    \n",
    "    return potential_targets\n",
    "\n",
    "\n",
    "def create_target_from_risk_features(df, threshold_percentile=90):\n",
    "    \"\"\"\n",
    "    Create binary risk label based on risk features.\n",
    "    \n",
    "    Strategy: Reports with high risk feature values are labeled as \"high risk\"\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"OPTION 1: CREATE TARGET FROM RISK FEATURES\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Get risk feature columns\n",
    "    risk_features = [col for col in df.columns if col.startswith('risk_')]\n",
    "    \n",
    "    if not risk_features:\n",
    "        print(\"ERROR: No risk features found\")\n",
    "        return df\n",
    "    \n",
    "    print(f\"\\nUsing risk features: {risk_features}\")\n",
    "    \n",
    "    # Calculate composite risk score\n",
    "    # Normalize each feature to 0-1 scale\n",
    "    df_normalized = df.copy()\n",
    "    for feature in risk_features:\n",
    "        max_val = df[feature].max()\n",
    "        if max_val > 0:\n",
    "            df_normalized[feature + '_norm'] = df[feature] / max_val\n",
    "        else:\n",
    "            df_normalized[feature + '_norm'] = 0\n",
    "    \n",
    "    # Calculate average normalized risk score\n",
    "    norm_features = [f + '_norm' for f in risk_features]\n",
    "    df['composite_risk_score'] = df_normalized[norm_features].mean(axis=1)\n",
    "    \n",
    "    # Create binary label based on threshold\n",
    "    threshold = df['composite_risk_score'].quantile(threshold_percentile / 100)\n",
    "    df['risk_label'] = (df['composite_risk_score'] >= threshold).astype(int)\n",
    "    \n",
    "    print(f\"\\nComposite risk score statistics:\")\n",
    "    print(f\"  Min:  {df['composite_risk_score'].min():.4f}\")\n",
    "    print(f\"  Mean: {df['composite_risk_score'].mean():.4f}\")\n",
    "    print(f\"  Max:  {df['composite_risk_score'].max():.4f}\")\n",
    "    print(f\"  Threshold ({threshold_percentile}th percentile): {threshold:.4f}\")\n",
    "    \n",
    "    print(f\"\\nRisk label distribution:\")\n",
    "    print(df['risk_label'].value_counts())\n",
    "    print(f\"\\n  Low Risk (0):  {(df['risk_label']==0).sum()} ({100*(df['risk_label']==0).sum()/len(df):.1f}%)\")\n",
    "    print(f\"  High Risk (1): {(df['risk_label']==1).sum()} ({100*(df['risk_label']==1).sum()/len(df):.1f}%)\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def create_target_from_sentiment(df):\n",
    "    \"\"\"\n",
    "    Create risk label from sentiment if available.\n",
    "    \n",
    "    Strategy: Negative sentiment = higher risk\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"OPTION 2: CREATE TARGET FROM SENTIMENT\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    if 'sentiment' not in df.columns:\n",
    "        print(\"ERROR: No 'sentiment' column found\")\n",
    "        return df\n",
    "    \n",
    "    print(f\"\\nSentiment values: {df['sentiment'].unique()}\")\n",
    "    \n",
    "    # Map sentiment to risk\n",
    "    # Assuming negative sentiment indicates higher risk\n",
    "    sentiment_map = {\n",
    "        'negative': 1,\n",
    "        'neutral': 0,\n",
    "        'positive': 0\n",
    "    }\n",
    "    \n",
    "    df['risk_label_from_sentiment'] = df['sentiment'].map(sentiment_map)\n",
    "    \n",
    "    if df['risk_label_from_sentiment'].isna().any():\n",
    "        print(f\"Warning: {df['risk_label_from_sentiment'].isna().sum()} unmapped sentiment values\")\n",
    "    \n",
    "    print(f\"\\nRisk label from sentiment distribution:\")\n",
    "    print(df['risk_label_from_sentiment'].value_counts())\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def create_target_from_load_factor(df, threshold=0.8):\n",
    "    \"\"\"\n",
    "    Create risk label from load_factor if available.\n",
    "    \n",
    "    Strategy: High load factor = higher operational risk\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"OPTION 3: CREATE TARGET FROM LOAD FACTOR\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    if 'load_factor' not in df.columns:\n",
    "        print(\"ERROR: No 'load_factor' column found\")\n",
    "        return df\n",
    "    \n",
    "    print(f\"\\nLoad factor statistics:\")\n",
    "    print(f\"  Min:  {df['load_factor'].min():.4f}\")\n",
    "    print(f\"  Mean: {df['load_factor'].mean():.4f}\")\n",
    "    print(f\"  Max:  {df['load_factor'].max():.4f}\")\n",
    "    \n",
    "    df['risk_label_from_load'] = (df['load_factor'] >= threshold).astype(int)\n",
    "    \n",
    "    print(f\"\\nUsing threshold: {threshold}\")\n",
    "    print(f\"Risk label from load factor distribution:\")\n",
    "    print(df['risk_label_from_load'].value_counts())\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def create_synthetic_target(df, high_risk_pct=2):\n",
    "    \"\"\"\n",
    "    Create synthetic risk labels for demonstration.\n",
    "    \n",
    "    Strategy: Use a combination of features to create realistic labels\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"OPTION 4: CREATE SYNTHETIC TARGET (DEMONSTRATION)\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    print(f\"\\nCreating synthetic labels with ~{high_risk_pct}% high-risk cases\")\n",
    "    \n",
    "    # Use risk features if available\n",
    "    risk_features = [col for col in df.columns if col.startswith('risk_')]\n",
    "    \n",
    "    if risk_features:\n",
    "        # Calculate risk score\n",
    "        df['risk_score'] = df[risk_features].sum(axis=1)\n",
    "        \n",
    "        # Add some randomness\n",
    "        np.random.seed(42)\n",
    "        noise = np.random.normal(0, df['risk_score'].std() * 0.1, size=len(df))\n",
    "        df['risk_score'] = df['risk_score'] + noise\n",
    "        \n",
    "        # Assign labels based on score percentile\n",
    "        threshold = df['risk_score'].quantile(1 - high_risk_pct/100)\n",
    "        df['risk_label_synthetic'] = (df['risk_score'] >= threshold).astype(int)\n",
    "    else:\n",
    "        # Pure random if no features\n",
    "        np.random.seed(42)\n",
    "        df['risk_label_synthetic'] = np.random.choice(\n",
    "            [0, 1], \n",
    "            size=len(df), \n",
    "            p=[1 - high_risk_pct/100, high_risk_pct/100]\n",
    "        )\n",
    "    \n",
    "    print(f\"\\nSynthetic risk label distribution:\")\n",
    "    print(df['risk_label_synthetic'].value_counts())\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def visualize_target_options(df, output_dir='figures'):\n",
    "    \"\"\"Visualize different target variable options.\"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"CREATING VISUALIZATIONS\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Find all label columns\n",
    "    label_cols = [col for col in df.columns if 'label' in col.lower()]\n",
    "    \n",
    "    if not label_cols:\n",
    "        print(\"No label columns to visualize\")\n",
    "        return\n",
    "    \n",
    "    # Risk features\n",
    "    risk_features = [col for col in df.columns if col.startswith('risk_') and 'label' not in col]\n",
    "    \n",
    "    if risk_features and label_cols:\n",
    "        # Plot risk features by different label definitions\n",
    "        for label_col in label_cols:\n",
    "            if label_col in df.columns and df[label_col].notna().all():\n",
    "                fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "                axes = axes.flatten()\n",
    "                \n",
    "                for idx, feature in enumerate(risk_features[:6]):\n",
    "                    if idx < len(axes):\n",
    "                        df.boxplot(column=feature, by=label_col, ax=axes[idx])\n",
    "                        axes[idx].set_title(f'{feature}')\n",
    "                        axes[idx].set_xlabel(f'{label_col}')\n",
    "                \n",
    "                plt.suptitle(f'Risk Features by {label_col}', y=1.02)\n",
    "                plt.tight_layout()\n",
    "                filename = f'{output_dir}/risk_features_by_{label_col}.png'\n",
    "                plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "                print(f\"  Saved: {filename}\")\n",
    "                plt.close()\n",
    "    \n",
    "    # Distribution comparison\n",
    "    if len(label_cols) > 1:\n",
    "        fig, axes = plt.subplots(1, len(label_cols), figsize=(5*len(label_cols), 4))\n",
    "        if len(label_cols) == 1:\n",
    "            axes = [axes]\n",
    "        \n",
    "        for idx, label_col in enumerate(label_cols):\n",
    "            if label_col in df.columns:\n",
    "                counts = df[label_col].value_counts()\n",
    "                axes[idx].bar(counts.index, counts.values)\n",
    "                axes[idx].set_title(f'{label_col}')\n",
    "                axes[idx].set_xlabel('Class')\n",
    "                axes[idx].set_ylabel('Count')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        filename = f'{output_dir}/label_distributions_comparison.png'\n",
    "        plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "        print(f\"  Saved: {filename}\")\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main execution function.\"\"\"\n",
    "    print(\"=\"*70)\n",
    "    print(\"CREATE TARGET VARIABLE FOR RISK CLASSIFICATION\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Load your processed data\n",
    "    data_path = 'data/processed/reports_with_features.csv'\n",
    "    \n",
    "    if not os.path.exists(data_path):\n",
    "        print(f\"\\nERROR: File not found: {data_path}\")\n",
    "        print(\"Please run script 02 first to create this file\")\n",
    "        return\n",
    "    \n",
    "    print(f\"\\nLoading data from: {data_path}\")\n",
    "    df = pd.read_csv(data_path)\n",
    "    print(f\"Loaded {len(df)} rows\")\n",
    "    \n",
    "    # Explore existing columns\n",
    "    potential_targets = explore_potential_targets(df)\n",
    "    \n",
    "    # Try different methods to create target\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"GENERATING TARGET VARIABLE OPTIONS\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Option 1: From risk features (RECOMMENDED)\n",
    "    df = create_target_from_risk_features(df, threshold_percentile=90)\n",
    "    \n",
    "    # Option 2: From sentiment (if available)\n",
    "    if 'sentiment' in df.columns:\n",
    "        df = create_target_from_sentiment(df)\n",
    "    \n",
    "    # Option 3: From load factor (if available)\n",
    "    if 'load_factor' in df.columns:\n",
    "        df = create_target_from_load_factor(df, threshold=0.8)\n",
    "    \n",
    "    # Option 4: Synthetic (fallback)\n",
    "    df = create_synthetic_target(df, high_risk_pct=2)\n",
    "    \n",
    "    # Visualize options\n",
    "    visualize_target_options(df)\n",
    "    \n",
    "    # RECOMMENDATION\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"RECOMMENDATION\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    print(\"\\nBased on your data, I recommend using: 'risk_label'\")\n",
    "    print(\"(Created from composite risk features)\")\n",
    "    print(\"\\nThis approach:\")\n",
    "    print(\"  ✓ Uses your actual risk features\")\n",
    "    print(\"  ✓ Creates realistic separation between classes\")\n",
    "    print(\"  ✓ Maintains interpretability\")\n",
    "    \n",
    "    # Save the dataset with the recommended label\n",
    "    output_path = 'data/processed/reports_with_features_and_labels.csv'\n",
    "    \n",
    "    # Keep the main risk_label, remove others\n",
    "    columns_to_keep = [col for col in df.columns if not (col.endswith('_norm') or col == 'risk_score')]\n",
    "    df_final = df[columns_to_keep].copy()\n",
    "    \n",
    "    df_final.to_csv(output_path, index=False)\n",
    "    print(f\"\\n✓ Saved dataset with labels to: {output_path}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"NEXT STEPS\")\n",
    "    print(\"=\"*70)\n",
    "    print(\"\\n1. Review the generated labels\")\n",
    "    print(\"2. If satisfied, update script 03 to use this file:\")\n",
    "    print(f\"   data_path = '{output_path}'\")\n",
    "    print(\"3. Or manually rename the column you want to use as 'risk_label'\")\n",
    "    \n",
    "    return df_final\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    df = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3802132e-7a22-44ef-90e2-58924b52714c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
