{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fa798c4d-2d2c-48b1-a800-a7b346564cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Import necessary Libraries\n",
    "# ============================================================\n",
    "\n",
    "import random\n",
    "import uuid\n",
    "from datetime import datetime, timedelta\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "216c595e-f69b-429f-8abf-8e22cc0c3743",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        id  timestamp                 style  \\\n",
      "1297  f550fcc8-6b63-4441-99d7-98f5af8c28d5 2024-02-12            risk_alert   \n",
      "2341  6d225ee9-1671-4f02-baf2-26c6b07e7631 2024-01-11  speculative_analysis   \n",
      "2926  b503098e-184c-41f3-8aee-e17e828f99e8 2024-09-20    casual_observation   \n",
      "2695  a14d296e-f77a-4328-83bf-e456d907f13e 2024-08-26    casual_observation   \n",
      "2225  d30a7269-e59f-402f-9057-06aebe31df66 2024-08-09            risk_alert   \n",
      "\n",
      "                       topic   sentiment  load_factor  agents  capacity  \\\n",
      "1297            traffic_flow   concerned         0.57     146       122   \n",
      "2341        system_stability  optimistic         0.40     403       228   \n",
      "2926  environmental_pressure     neutral         0.52     152       126   \n",
      "2695  environmental_pressure   concerned         0.44     457        83   \n",
      "2225     resource_allocation     neutral         0.33     346        85   \n",
      "\n",
      "                                                   text  \n",
      "1297  Attention required: that traffic flow was like...  \n",
      "2341  It may be that that system stability cannot be...  \n",
      "2926  There seems to be that environmental pressure ...  \n",
      "2695  We’re starting to see that environmental press...  \n",
      "2225  Warning: that resource allocation could decrea...  \n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Core configuration\n",
    "# ============================================================\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "N_SAMPLES = 3000\n",
    "\n",
    "STYLES = [\n",
    "    \"formal_report\",\n",
    "    \"technical_summary\",\n",
    "    \"casual_observation\",\n",
    "    \"speculative_analysis\",\n",
    "    \"risk_alert\"\n",
    "]\n",
    "\n",
    "TOPICS = [\n",
    "    \"infrastructure_load\",\n",
    "    \"traffic_flow\",\n",
    "    \"system_stability\",\n",
    "    \"environmental_pressure\",\n",
    "    \"resource_allocation\"\n",
    "]\n",
    "\n",
    "SENTIMENTS = [\"neutral\", \"cautious\", \"optimistic\", \"concerned\"]\n",
    "\n",
    "# ============================================================\n",
    "# Language primitives (variation is critical for NLP)\n",
    "# ============================================================\n",
    "\n",
    "OPENINGS = {\n",
    "    \"formal_report\": [\n",
    "        \"This report outlines\",\n",
    "        \"The following assessment evaluates\",\n",
    "        \"An analysis was conducted to determine\"\n",
    "    ],\n",
    "    \"technical_summary\": [\n",
    "        \"Simulation results indicate\",\n",
    "        \"Observed system metrics suggest\",\n",
    "        \"Model outputs reveal\"\n",
    "    ],\n",
    "    \"casual_observation\": [\n",
    "        \"It looks like\",\n",
    "        \"We’re starting to see\",\n",
    "        \"There seems to be\"\n",
    "    ],\n",
    "    \"speculative_analysis\": [\n",
    "        \"One possible explanation is\",\n",
    "        \"A plausible interpretation is\",\n",
    "        \"It may be that\"\n",
    "    ],\n",
    "    \"risk_alert\": [\n",
    "        \"Warning:\",\n",
    "        \"Attention required:\",\n",
    "        \"Potential issue detected:\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "VERBS = [\n",
    "    \"increase\", \"decrease\", \"stabilize\",\n",
    "    \"accelerate\", \"degrade\", \"fluctuate\"\n",
    "]\n",
    "\n",
    "MODIFIERS = [\n",
    "    \"slightly\", \"moderately\", \"significantly\",\n",
    "    \"unexpectedly\", \"gradually\", \"rapidly\"\n",
    "]\n",
    "\n",
    "OUTCOMES = [\n",
    "    \"system performance\",\n",
    "    \"network efficiency\",\n",
    "    \"operational reliability\",\n",
    "    \"resource utilization\",\n",
    "    \"risk exposure\"\n",
    "]\n",
    "\n",
    "HEDGING = [\n",
    "    \"may\", \"might\", \"could\",\n",
    "    \"appears to\", \"is likely to\", \"cannot be ruled out\"\n",
    "]\n",
    "\n",
    "# ============================================================\n",
    "# Helper functions\n",
    "# ============================================================\n",
    "\n",
    "def random_date():\n",
    "    start = datetime(2024, 1, 1)\n",
    "    return start + timedelta(days=random.randint(0, 365))\n",
    "\n",
    "def generate_numeric_context():\n",
    "    return {\n",
    "        \"load_factor\": round(np.random.beta(2, 5), 2),\n",
    "        \"capacity\": random.randint(50, 300),\n",
    "        \"agents\": random.randint(10, 500)\n",
    "    }\n",
    "\n",
    "def inject_noise(text):\n",
    "    \"\"\"Adds minor grammatical / stylistic noise\"\"\"\n",
    "    if random.random() < 0.2:\n",
    "        text += \".\"\n",
    "    if random.random() < 0.15:\n",
    "        text = text.replace(\" is \", \" was \")\n",
    "    return text\n",
    "\n",
    "# ============================================================\n",
    "# Main text generation\n",
    "# ============================================================\n",
    "\n",
    "def generate_text(style, topic, sentiment, metrics):\n",
    "    opening = random.choice(OPENINGS[style])\n",
    "    verb = random.choice(VERBS)\n",
    "    modifier = random.choice(MODIFIERS)\n",
    "    outcome = random.choice(OUTCOMES)\n",
    "    hedge = random.choice(HEDGING)\n",
    "\n",
    "    base_sentence = (\n",
    "        f\"{opening} that {topic.replace('_', ' ')} \"\n",
    "        f\"{hedge} {verb} {modifier}, impacting {outcome}.\"\n",
    "    )\n",
    "\n",
    "    numeric_sentence = (\n",
    "        f\" Current load is {metrics['load_factor']} \"\n",
    "        f\"with {metrics['agents']} active agents \"\n",
    "        f\"against a capacity of {metrics['capacity']}.\"\n",
    "    )\n",
    "\n",
    "    if sentiment == \"concerned\":\n",
    "        numeric_sentence += \" This raises concerns about future stability.\"\n",
    "    elif sentiment == \"optimistic\":\n",
    "        numeric_sentence += \" Conditions remain within acceptable bounds.\"\n",
    "\n",
    "    text = base_sentence + numeric_sentence\n",
    "    return inject_noise(text)\n",
    "\n",
    "# ============================================================\n",
    "# Dataset generation\n",
    "# ============================================================\n",
    "\n",
    "def generate_dataset(n=N_SAMPLES):\n",
    "    records = []\n",
    "\n",
    "    for _ in range(n):\n",
    "        style = random.choice(STYLES)\n",
    "        topic = random.choice(TOPICS)\n",
    "        sentiment = random.choice(SENTIMENTS)\n",
    "        metrics = generate_numeric_context()\n",
    "\n",
    "        record = {\n",
    "            \"id\": str(uuid.uuid4()),\n",
    "            \"timestamp\": random_date(),\n",
    "            \"style\": style,\n",
    "            \"topic\": topic,\n",
    "            \"sentiment\": sentiment,\n",
    "            \"load_factor\": metrics[\"load_factor\"],\n",
    "            \"agents\": metrics[\"agents\"],\n",
    "            \"capacity\": metrics[\"capacity\"],\n",
    "            \"text\": generate_text(style, topic, sentiment, metrics)\n",
    "        }\n",
    "\n",
    "        records.append(record)\n",
    "\n",
    "    return pd.DataFrame(records)\n",
    "\n",
    "# ============================================================\n",
    "# Run\n",
    "# ============================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    df = generate_dataset()\n",
    "    print(df.sample(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9202e74b-455a-4358-bac3-afc8dfd92d94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 3000 rows to synthetic_nlp_dataset.csv\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Save to CSV\n",
    "# ============================================================\n",
    "\n",
    "df.to_csv(\"synthetic_nlp_dataset.csv\", index=False)\n",
    "print(f\"Saved {len(df)} rows to synthetic_nlp_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d51c493b-d3ff-489d-bd9f-3fcda1b4aee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== BASIC SHAPE =====\n",
      "(3000, 9)\n",
      "\n",
      "===== MISSING VALUES =====\n",
      "id             0\n",
      "timestamp      0\n",
      "style          0\n",
      "topic          0\n",
      "sentiment      0\n",
      "load_factor    0\n",
      "agents         0\n",
      "capacity       0\n",
      "text           0\n",
      "dtype: int64\n",
      "\n",
      "===== LABEL DISTRIBUTIONS =====\n",
      "\n",
      "STYLE\n",
      "style\n",
      "formal_report           0.210667\n",
      "speculative_analysis    0.202667\n",
      "casual_observation      0.199667\n",
      "risk_alert              0.196000\n",
      "technical_summary       0.191000\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "TOPIC\n",
      "topic\n",
      "resource_allocation       0.209667\n",
      "traffic_flow              0.204333\n",
      "system_stability          0.199000\n",
      "infrastructure_load       0.193667\n",
      "environmental_pressure    0.193333\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "SENTIMENT\n",
      "sentiment\n",
      "cautious      0.267667\n",
      "concerned     0.246667\n",
      "neutral       0.243667\n",
      "optimistic    0.242000\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "===== DUPLICATE TEXT CHECK =====\n",
      "Duplicate text rate: 0.000\n",
      "\n",
      "===== TEXT LENGTH DIVERSITY =====\n",
      "count    3000.000000\n",
      "mean       29.180667\n",
      "std         3.218925\n",
      "min        23.000000\n",
      "25%        26.000000\n",
      "50%        29.000000\n",
      "75%        32.000000\n",
      "max        37.000000\n",
      "Name: text, dtype: float64\n",
      "\n",
      "===== NUMERIC ↔ TEXT SANITY CHECK =====\n",
      "High-load frequent terms: [('load', 30), ('that', 27), ('is', 26), ('impacting', 25), ('Current', 25), ('with', 25), ('active', 25), ('agents', 25), ('against', 25), ('a', 25)]\n",
      "Low-load frequent terms: [('load', 2009), ('is', 1875), ('that', 1829), ('impacting', 1693), ('Current', 1693), ('with', 1693), ('active', 1693), ('agents', 1693), ('against', 1693), ('a', 1693)]\n",
      "\n",
      "✅ Dataset validation passed.\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Validate the Data\n",
    "# ============================================================\n",
    "\n",
    "def validate_dataset(df):\n",
    "    print(\"===== BASIC SHAPE =====\")\n",
    "    print(df.shape)\n",
    "    print()\n",
    "\n",
    "    print(\"===== MISSING VALUES =====\")\n",
    "    print(df.isnull().sum())\n",
    "    print()\n",
    "\n",
    "    print(\"===== LABEL DISTRIBUTIONS =====\")\n",
    "    for col in [\"style\", \"topic\", \"sentiment\"]:\n",
    "        print(f\"\\n{col.upper()}\")\n",
    "        print(df[col].value_counts(normalize=True))\n",
    "    print()\n",
    "\n",
    "    print(\"===== DUPLICATE TEXT CHECK =====\")\n",
    "    dup_rate = df[\"text\"].duplicated().mean()\n",
    "    print(f\"Duplicate text rate: {dup_rate:.3f}\")\n",
    "    assert dup_rate < 0.02, \"Too many duplicate samples\"\n",
    "    print()\n",
    "\n",
    "    print(\"===== TEXT LENGTH DIVERSITY =====\")\n",
    "    lengths = df[\"text\"].str.split().apply(len)\n",
    "    print(lengths.describe())\n",
    "    print()\n",
    "\n",
    "    print(\"===== NUMERIC ↔ TEXT SANITY CHECK =====\")\n",
    "    high_load = df[df[\"load_factor\"] > 0.7][\"text\"]\n",
    "    low_load = df[df[\"load_factor\"] < 0.3][\"text\"]\n",
    "\n",
    "    high_terms = Counter(\" \".join(high_load).split()).most_common(10)\n",
    "    low_terms = Counter(\" \".join(low_load).split()).most_common(10)\n",
    "\n",
    "    print(\"High-load frequent terms:\", high_terms)\n",
    "    print(\"Low-load frequent terms:\", low_terms)\n",
    "    print()\n",
    "\n",
    "    print(\"✅ Dataset validation passed.\")\n",
    "\n",
    "# Run validation\n",
    "validate_dataset(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
